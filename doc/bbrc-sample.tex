% This is "sig-alternate.tex" V1.9 April 2009
% This file should be compiled with V2.4 of "sig-alternate.cls" April 2009
%
% This example file demonstrates the use of the 'sig-alternate.cls'
% V2.4 LaTeX2e document class file. It is for those submitting
% articles to ACM Conference Proceedings WHO DO NOT WISH TO
% STRICTLY ADHERE TO THE SIGS (PUBS-BOARD-ENDORSED) STYLE.
% The 'sig-alternate.cls' file will produce a similar-looking,
% albeit, 'tighter' paper resulting in, invariably, fewer pages.
%
% ----------------------------------------------------------------------------------------------------------------
% This .tex file (and associated .cls V2.4) produces:
%       1) The Permission Statement
%       2) The Conference (location) Info information
%       3) The Copyright Line with ACM data
%       4) NO page numbers
%
% as against the acm_proc_article-sp.cls file which
% DOES NOT produce 1) thru' 3) above.
%
% Using 'sig-alternate.cls' you have control, however, from within
% the source .tex file, over both the CopyrightYear
% (defaulted to 200X) and the ACM Copyright Data
% (defaulted to X-XXXXX-XX-X/XX/XX).
% e.g.
% \CopyrightYear{2007} will cause 2007 to appear in the copyright line.
% \crdata{0-12345-67-8/90/12} will cause 0-12345-67-8/90/12 to appear in the copyright line.
%
% ---------------------------------------------------------------------------------------------------------------
% This .tex source is an example which *does* use
% the .bib file (from which the .bbl file % is produced).
% REMEMBER HOWEVER: After having produced the .bbl file,
% and prior to final submission, you *NEED* to 'insert'
% your .bbl file into your source .tex file so as to provide
% ONE 'self-contained' source file.
%
% ================= IF YOU HAVE QUESTIONS =======================
% Questions regarding the SIGS styles, SIGS policies and
% procedures, Conferences etc. should be sent to
% Adrienne Griscti (griscti@acm.org)
%
% Technical questions _only_ to
% Gerald Murray (murray@hq.acm.org)
% ===============================================================
%
% For tracking purposes - this is V1.9 - April 2009

\documentclass{sig-alternate}
  \pdfpagewidth=8.5truein
  \pdfpageheight=11truein

\makeatletter
\newif\if@restonecol
\makeatother
\let\algorithm\relax
\let\endalgorithm\relax


\usepackage{multirow}	% for tables
\usepackage{graphicx}   % for including EPS
\usepackage{rotating}
\usepackage{url}

% % % Special mathematical fonts
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{bm}
\usepackage{srctex}
\usepackage[linesnumbered,algo2e,noend]{algorithm2e}
\usepackage{algpseudocode}
\usepackage{setspace}
%\usepackage[compact]{titlesec}
%\usepackage{mdwlist}
%\usepackage[left=2cm,top=1cm,right=2cm,nohead,nofoot]{geometry}

\algnotext{EndFor}
\algnotext{EndIf}

\begin{document}
%
% --- Author Metadata here ---
\conferenceinfo{SAC'13}{March 18-22, 2013, Coimbra, Portugal.}
\CopyrightYear{2013} % Allows default copyright year (2002) to be over-ridden - IF NEED BE.
\crdata{978-1-4503-1656-9/13/03}  % Allows default copyright data (X-XXXXX-XX-X/XX/XX) to be over-ridden.
% --- End of Author Metadata ---

\title{Out-Of-Bag Discriminative Graph Mining}
%
% You need the command \numberofauthors to handle the 'placement
% and alignment' of the authors beneath the title.
%
% For aesthetic reasons, we recommend 'three authors at a time'
% i.e. three 'name/affiliation blocks' be placed beneath the title.
%
% NOTE: You are NOT restricted in how many 'rows' of
% "name/affiliations" may appear. We just ask that you restrict
% the number of 'columns' to three.
%
% Because of the available 'opening page real-estate'
% we ask you to refrain from putting more than six authors
% (two rows with three columns) beneath the article title.
% More than six makes the first-page appear very cluttered indeed.
%
% Use the \alignauthor commands to handle the names
% and affiliations for an 'aesthetic maximum' of six authors.
% Add names, affiliations, addresses for
% the seventh etc. author(s) as the argument for the
% \additionalauthors command.
% These 'additional authors' will be output/set for you
% without further effort on your part as the last section in
% the body of your article BEFORE References or any Appendices.

\numberofauthors{3} %  in this sample file, there are a *total*
% of EIGHT authors. SIX appear on the 'first-page' (for formatting
% reasons) and the remaining two appear in the \additionalauthors section.
%
\author{
% You can go ahead and credit any number of authors here,
% e.g. one 'row of three' or two rows (consisting of one row of three
% and a second row of one, two or three).
%
% The command \alignauthor (no curly braces needed) should
% precede each author name, affiliation/snail-mail address and
% e-mail address. Additionally, tag each line of
% affiliation/address with \affaddr, and tag the
% e-mail address with \email.
%
% 1st. author
\alignauthor
Andreas Maunz\\
       \affaddr{Institute for Physics}\\
       \affaddr{Hermann-Herder-Str. 3}\\
       \affaddr{79194 Freiburg, Germany}\\
       \email{andreas@maunz.de}
% 2nd. author
\alignauthor David Vorgrimmler\\
       \affaddr{in-silico Toxicology}\\
       \affaddr{Altkircherstr. 4}\\
       \affaddr{4054 Basel, Switzerland}\\
       \email{vorgrimmler@in-silico.ch}
% 3rd. author
\alignauthor 
Christoph Helma\\
       \affaddr{in-silico Toxicology}\\
       \affaddr{Altkircherstr. 4}\\
       \affaddr{4054 Basel, Switzerland}\\
       \email{helma@in-silico.ch}
}

\maketitle
\begin{abstract}
  In class-labeled graph databases, each graph is associated with one from a
finite set of classes, which induces associations between the latter and subgraphs
occurring in the database graphs. The subgraphs with strong
class associations are called discriminative subgraphs.  In this work,
discriminative subgraphs are repeatedly mined on bootstrap samples of a graph
database in order to estimate the subgraph associations.  This is
done by recording the subgraph occurrence frequencies (support values) per class over the
out-of-bag instances of the bootstrap process.  We investigate two different
methods for the approximation of the true underlying support values from these
empirical values, involving sample mean and maximum likelihood estimation.  We
show that both methods significantly improve the process, compared to single
runs of discriminative graph mining, by applying the different methods to
publicly available toxicological datasets.  In computational models of toxicology,
subgraphs (fragments of chemical structure) are routinely used to describe
molecules. Apart from the subgraph associations being
statistically validated, the subgraph set sizes created by the proposed methods are
much reduced, compared to ordinary discriminative graph mining, and may thus be beneficial
for statistical models, as well as for inspection by toxicological experts.


\end{abstract}



% A category with the (minimum) three required fields
\category{H.2.8}{Database Applications}{Data Mining, Statistical Databases}
\terms{Theory, Experimentation, Performance}

\section{Introduction}
\label{s:Introduction}
Given a class-labeled graph database, discriminative graph mining is a
supervised learning task with the goal to extract graph fragments (subgraphs)
with strong associations to the classes, according to statistical constraints
set by the user. For example, the subgraphs may be molecular fragments that
induce toxicity. Indeed, finding such subgraphs is a major goal in toxicology
\cite{kazius05derivation}. However, discriminative graph mining yields large
result sets, even for very tight constraints on subgraph significance ($p$-values) \cite{Jun04Spin}. Moreover, it is an unstable
process, i.e. slight changes in the sample may lead to substantially different subgraph
sets. 

A bagged predictor consists of several aggregate predictors, each trained on a
dedicated bootstrap sample of the training data. Bagged predictors have the
potential for considerably higher predictive accuracy, compared to single
predictors, especially in the context of unstable prediction methods
\cite{breiman96oob}. For example, out-of-bag estimation of node errors in
decision trees could improve on estimates obtained from the training data as a
whole \cite{breiman96oob}. Bagged predictor estimates may be obtained from the out-of-bag
instances, which saves computational effort compared to crossvalidation on the
bootstrap samples. 

This work extends discriminative subgraph mining by out-of-bag estimation for
subgraph frequencies on the classes that govern the
training data (support values), and by aggregating subgraphs in the output that pass the
statistical constraints.  Infrequently occurring subgraphs are filtered out, 
which removes the instability to a large extent. This yields statistically validated, highly significant,
discriminative subgraphs, which may be useful for diagnostic or predictive
modelling, or for expert inspection. 

The remainder of this work is structured as follows: We present related work
with a focus on discriminative graph mining (section \ref{s:relatedWork}), our
proposed methods for out-of-bag estimation of support values, as
well as algorithmic implementation (section \ref{s:Methods}).
Experiments include validation of subgraph support
values, $p$-values, and class bias on publicly available databases of
various sizes and numbers of classes (section \ref{s:Experiments}).
We draw conclusions in section \ref{s:Conclusion}.
The contributions of this work are summarized as follows:
\begin{itemize}
  \item Repeated discriminative graph mining on bootstrap samples of a
    class-labeled graph database is proposed as a means to stabilize estimates
    for subgraph properties, such as support values per class, compared to
    single runs of discriminative graph mining. The estimation is performed
    using the out-of-bag instances of the individual bootstrap samples.
  \item Two methods for the estimation of support values are described, where both
    handle multiple class values. Significance tests are applied to these
    estimated values and insignificant subgraphs are removed from the results.  
  \item The estimated support values, $p$-values, and class
    associations are empirically validated on molecular databases of various
    sizes.  The results indicate significant improvements over 
    ordinary discriminative graph mining, where the effect is generally larger the
    smaller the datasets are.  We conclude that out-of-bag estimation has 
    potential to generate concise, discriminative subgraph sets for
    use in statistical models and/or expert inspection.
\end{itemize}


\section{Related Work}
\label{s:relatedWork}

Out-of-bag methods have been used to robustly estimate node probabilities and
node error rates in decision trees \cite{breiman96oob} as well as the
generalization error and accuracy of bagged predictors. In the work by Bylander
\cite{bylander02estimating}, generalization error was well modeled by
out-of-bag estimation, and its already small bias could be further reduced by a
correction method, where, in order to correct the prediction of a given
instance, similar out-of-bag instances with the same class were
employed. However, the method of out-of-bag estimation is not confined to these
examples, and may be used to estimate other statistical properties in
supervised learning.

Discriminative graph mining is often employed as a preprocessing step to
statistical learning, because discriminative subgraphs may be useful as descriptors
\cite{bringmann10lego}. Nowadays, there is a variety of well-known statistical
learning algorithms available ``off the shelf'', which makes a workflow
attractive where subgraphs are extracted from the data, represented in a
unified format, and fed into a machine learning algorithm \cite{hkr03molfea}.
Usually, discriminative subgraphs are mined from a graph database using a
predefined threshold with regard to target class associations. A subgraph
qualifies for the result set if it passes a corresponding significance test.
However, such approaches tend to produce huge sets of very similar subgraphs,
even with very tight bounds on discriminative power, which would prevent
machine learning methods from building models in acceptable time, and post-processing would be required to lower redundancy and eliminate the vast
majority of subgraphs \cite{Hasan_origami:mining,Jun04Spin}.  Moreover, the
result is not stable with regards to perturbations of the database.

Subgraph boosting \cite{saigo09gboost} is an integrated approach to build models on
small sets of subgraphs, alternating between graph mining and model building. The method presented here is clearly
different from boosting, because it calculates subgraphs independently from a specific model.  It is similar in that it calculates a small
collection of discriminative subgraphs, but it is also stable against
perturbations of the database, which is generally not the case for boosting.


\section{Methods}
\label{s:Methods}

\subsection{Basic Graph Theory}
\label{ss:BasicGraphTheory}
A graph database is a tuple $(G, \Sigma, a)$, where $G$ is a set of graphs,
$\Sigma \ne \emptyset$  is a totally ordered set of labels and $a: G
\rightarrow I$, $I \subset \mathbb{N}$, is a function that assigns one from a
finite set of class values to every graph in the database.  The set of target
classes $I$ consists of at least two values.  We consider labeled, undirected
graphs, i.e. tuples $g=(V,E,\Sigma,\lambda)$, where $V\ne \emptyset$ is a
finite set of nodes and $E \subseteq V = \{\{v_1, v_2\} \in \{V \times V\}, v_1
\ne v_2\}$ is a set of edges and $\lambda: V\cup E \rightarrow \Sigma$ is a
label function.  
An ordered set of nodes $\{ v_1, \ldots, v_m\}$ is a \emph{path} between $v_1$ and $v_m$, if $\{v_i, v_{i+1}\} \in E, i \in \{1,\ldots,m-1\}$ and $v_i \neq v_j$ for all $i,j\in \{1,\ldots,m\}$.
We only consider connected graphs here, i.e.  there is a path
between each two nodes in the graph.

A graph $g'=(V',E',\Sigma',\lambda')$ subgraph-isomorphic to $g$ if $V'
\subseteq V$ and $E' \subseteq E$ with $V' \ne \emptyset$ and $E' \ne
\emptyset$, $\lambda'(v_1)=\lambda(v_2)$ whenever $v_1=v_2$, and
$\lambda'(e_1)=\lambda(e_2)$ whenever $e_1=e_2$, for all nodes and edges in
$g'$. Then, graph $g'$ is also referred to as a subgraph of $g$ -- we also say
that $g'$ covers $g$.  The subset of the database instances $G$ that $g'$
covers is referred to as the occurrences of $g'$, and its size as (total) support of
$g'$.  As a special case, the size of the subset of occurrences with $a(g)=i$,
for any $g$ in the occurrences, is referred to as the support of $g'$ for class
$i$. Thus, any subgraph has associated support values per class, ranging each
between 0 and the support of $g'$, and summing up to the the support of $g'$.

The subgraphs considered in this work are free subtrees. Here, we define a tree
as a graph with exactly $n-1$ edges that connect its $n$ nodes. A free tree is
a tree without a designated root node. For an introduction to tree mining and
the terminology used there, see the overview by Chi \emph{et al.}
\cite{CMNK01Frequent}.

\subsection{Significance Test}
\label{ss:significance-test}
% general chisq test
For a given subgraph $g$, we seek a $|I| \times 2$ contingency table that lists the
support values per class in the first column and the overall distribution of target
classes in the second column, as in Table \ref{t-ContingencyTableIndTest}.
\begin{table}[t]
  \centering
  \begin{tabular}{|l|l|l|}
    \hline
    ~           &	$g$       & $all$       \\\hline
    class 1	    &	$k_1$     & $|G^1|$     \\\hline
    class 2 	  &	$k_2$     & $|G^2|$     \\\hline
    $\ldots$ 	  &	$\ldots$  & $\ldots$    \\\hline
    class $|I|$	&	$k_{|I|}$ & $|G^{|I|}|$ \\\hline
    $\Sigma$	  &	$k$       & $|G|$       \\\hline
  \end{tabular}
  \caption[]{Contingency table for subgraph $g$.}
  \label{t-ContingencyTableIndTest}
\end{table}
This data serves to check whether $g$'s support values differ
significantly from the overall class distribution.  The $\chi^2_d$ function for
distribution testing, defined as
\begin{equation}
  %\chi^2_d(x,y) = \frac{(y-\frac{xm}{n})^2}{\frac{xm}{n}} + \frac{(x-y-\frac{x(n-m)}{n})^2}{\frac{x(n-m)}{n}},
  \chi^2_d(x,y) = \sum_{i=1}^{|I|} \frac{(k_i-E(k_i))^2}{E(k_i)},
  \label{eq:chid}
\end{equation} 
where $E(k_i)=\frac{G^{i}k}{|G|}$ is the expected value of $k_i$, calculates
the sum of squares of deviations from the expected support for all target
classes. The function value is then compared against the $\chi^2$
distribution function to obtain a $p$-value and conduct a significance test with
$|I|-1$ degrees of freedom.  The $|G^{i}|$ entries are constants and take the values of
the overall $|G^{i}|$.  This is possible due to the stratified bootstrapping approach,
which maintains the overall class proportions in each sample (see section
\ref{ss:oob-dgm}). 
Additionally, the bias of $g$ is determined as $\arg\max_i (\frac{k_i}{k}/\frac{G^i}{G})$, to designate the dominant class for $g$.
The next sections discuss methods to obtain the
$k_i$ entries in the table from the support values obtained during bootstrapping (section
\ref{ss:oob-dgm}).  


\subsection{Out-Of-Bag Discriminative Graph Mining}
\label{ss:oob-dgm}
We refer to the subset that contains all the graphs $g \in G$
with $a(g)=i$ as $G^i$.  The procedure first splits the graph database 
into stratified, equal-sized training and test databases $G_{Train}$ and $G_{Test}$.
Subsequently, stratified bootstrapping is performed on $G_{Train}$, such
that each sample comprises $\vert G_{Train}^i\vert$ graphs associated with
class $i$, drawn with replacement and uniform probability inside 
class $i$, for all $i$ in $I$.  On average, about 37\% (1/$e$) of training instances 
will not be drawn in any bootstrap sample (out-of-bag instances). 
Next, discriminative subgraphs are mined from the drawn instances,
according to minimum total support and significance thresholds. 
Each subgraph in the result set has associated support values, $p$-value, 
and bias, as calculated on the bootstrap sample.
Finally, the method re-assesses the support values by performing isomorphism
tests with the result subgraphs on the out-of-bag instances (``matching''), and records these values as follows:

Bootstrapping and graph mining is repeated $N$ times on $G_{Train}$, where in each
iteration, pairs of subgraphs and out-of-bag support values per class
$(g,k_1,\ldots,k_{\vert I\vert})$ are produced, meaning that subgraph $g$
occurs in $k_i$ out-of-bag graphs associated with class $i$. The results are
recorded over the $N$ bootstrap samples, such that for each $g$, the list of
support values is a tuple $(\mathbf{k_1}\ldots\mathbf{k_{\vert I\vert}})$,
where $\mathbf{k_i}$ is a vector $(k_i^1\ldots k_i^N)$, containing all the
support values.  
The vectors $\mathbf{k_i}$
are generally sparse (contain missing values), due to the instability of discriminative graph mining,
i.e. perturbations to the dataset (such as bootstrap sampling) yield almost
always a different (but partially overlapping) selection of subgraphs. To cope with the
variety of rare subgraphs, a fixed threshold removes all subgraphs with less
than $\lfloor0.3*N\rfloor$ entries in the list of support values, after the end
of bootstrapping.
The total support is determined from the class specific support values by
summing up vectors $\mathbf{k_i}$ across classes:
$\mathbf{k}=\sum_{i=1}^{\vert I\vert} \mathbf{k_i}$. 

From the recorded results, support values, $p$-value, 
and bias are estimated. Two methods, described in the next sections, are employed, based either
on the sample mean support per class, and using data of the current subgraph
only, or on a maximum likelihood estimate, involving some of the other
subgraphs. Then, the significance test from section \ref{ss:significance-test}
is run on the estimated support values. 

\subsubsection{Sample Mean Method}
\label{ss:simple-mean}
We set the value of $k_i$ in Table \ref{t-ContingencyTableIndTest} to
$\overline{\mathbf{k_i}}$, i.e. the sample mean
across the entries of vector $\mathbf{k_i}$ (ignoring missing values), for all $i \in \{1,\ldots,|I|\}$,
and $k$ is the sum of the $k_i$.

\subsubsection{Maximum Likelihood Estimation Method}
\label{ss:MLE}
Here, we employ some of the other subgraphs to form estimates for the $k_i$.
The first step in this process is to extract the subgraphs with the same class
bias as $g$ (see section \ref{ss:significance-test}).  Local ties are broken in
favor of the dominant global class. In case of a further tie on the global
level, one of the globally dominant classes is chosen with uniform probability.
In a second step, the subgraphs with the same class bias as $g$ are used to correct
$g$'s local frequencies by weighting. This approach has some similarity to the
work by Bylander \cite{bylander02estimating}, however, his aim is to correct
instance predictions, and his correction employs similar out-of-bag instances,
whereas our correction happens across bootstraps, and on the subgraphs (not
instances) obtained collectively from all the bootstrap samples.  For each
class, we model the event that each $k_i^j \in \mathbf{k_i}$ would occur for
each of the subgraphs with the same class bias as $g$ as a multinomial
selection process.  More specifically, we determine the class probabilities for
each subgraph $g'$ with the same class bias as $g$ with a maximum likelihood
estimator. It is the smoothed vector of relative class specific support values,
defined as:
\begin{equation}
  \mathbf{\alpha_{g'}} = \left(\frac{1+\vert\mathbf{k_1}\vert_1}{\vert I\vert+\vert\mathbf{k}\vert}_1,\ldots,\frac{1+\vert\mathbf{k_{\vert I\vert}}\vert_1}{\vert I\vert+\vert\mathbf{k}\vert_1}\right)
  \label{eqn:mlexpr}
\end{equation}
where the $\mathbf{k_i}$ and $\mathbf{k}$ pertain to $g'$, and $\vert\cdot\vert_1$ is the one-norm (the sum of the vector elements, ignoring missing values). Following that, for
each non-missing tuple $(k_1^j,\ldots,k_{\vert I\vert}^j)$ pertaining to $g$, a probability distribution is
determined from this collection of multinomials:
\begin{equation}
  p((k_1^j,\ldots,k_{\vert I\vert}^j))=\frac{\sum_{g'} p((k_1^j,\ldots,k_{\vert I\vert}^j); \mathbf{\alpha_{g'}})}{\sum_{g'}1}
  \label{eqn:avgpr}
\end{equation}
Finally, the $k_i^j$ values pertaining to $g$ are corrected in a weighted average
based on this probability distribution:
\begin{equation}
  \overline{\mathbf{k_i}}=\frac{\sum_j k_i^j p((k_1^j,\ldots,k_{\vert I\vert}^j))}{\sum_j p((k_1^j,\ldots,k_{\vert I\vert}^j))}
  \label{eqn:avgki}
\end{equation}
Again, we set the value of $k_i$ in Table \ref{t-ContingencyTableIndTest} to $\overline{\mathbf{k_i}}$.

\subsection{Algorithm}
\label{s:Algorithm}
%\begin{figure*}[t]
%  \begin{center}
%    \includegraphics[width=9cm]{classes.eps}
%  \end{center}
%  \caption{Two non-disjoint partitions $(a,b,d)$ and $(a,c,d)$. The members are ordered by subgraph relationship.}
%  \label{fig:bbrc}
%\end{figure*}
%According to section \ref{ss:oob-dgm}, graph mining proceeds in two steps:
%mining the given bootstrap sample and -- for each subgraph found -- looking up
%support values per class by matching on the out-of-bag instances.  
The mining step from section \ref{ss:oob-dgm} may be 
implemented using a discriminative graph mining algorithm of choice as ``mother algorithm''. Here, we
employ backbone refinement class mining (BBRC) \cite{maunz11efficient}. It
achieves a certain degree of compression by partitioning the subgraph search space into non-disjoint sets (classes) with the same
longest paths (backbones) and selecting only one representative from each
class. 
%Inside each partition, the patterns are ordered by the subgraph relationship (see figure \ref{fig:bbrc}). 
The representative is chosen to minimize the $p$-value (section \ref{ss:significance-test}), unless no member passes the user-defined significance constraint, in which case no representative is chosen.
The search is also bounded by minimum total support, as described in section \ref{ss:oob-dgm}.
In the BBRC output, two isomorphic subgraphs are always represented by the same string identifier.
We employ SMARTS strings as identifiers, a kind of regular expression to encode
molecular fragments as strings\footnote{see \url{http://www.daylight.com/dayhtml/doc/theory/theory.smarts.html}}.  This approach allows to store out-of-bag support values $\mathbf{k_i}$ in a
hash structure, using SMARTS as keys. 

\begin{algorithm2e*}[t]
  \fontsize{8}{10}
  \selectfont
  \KwData{$dataBase, numBoots, minHashLength, method, minSupport, alpha$}
  \KwResult{$[subgraphs, values]$ \text{; $values$ include support, $p$-values, and bias}}
  \If{$method=$\text{ODGM}}{
     $[subgraphs, values] \leftarrow BBRC(dataBase, minSupport, alpha)$\;
  }
  \Else{
    $hashTable \leftarrow \{\}$\;
    \For{$i:=1 \to numBoots$ (Parallel Processing)} { 
      $sample,OOB \leftarrow drawBsSample(dataBase)$\;
      $[subgraphs, values] \leftarrow BBRC(sample, minSupport, alpha)$\;
      $insert(hashTable,match(subgraphs,OOB))$\;
    }
    $[subgraphs, values] \leftarrow []$\;
    \For{$subgraph \in keys(hashTable)$}{
      \If{$length(hashTable[subgraph]) \geq minHashLength$}{
         $[candidateSupportValues, candidatePValue, candidateBias] \leftarrow method(hashTable[subgraph])$\;
        \If{$candidatePValue < alpha$}{
          $subgraphs \leftarrow subgraphs \cup subgraph$\;
          $values \leftarrow values \cup [candidateSupportValues, candidatePValue, candidateBias]$\;
        }
      }
    }
  }
  \caption{Calculation of subgraph significance on out-of-bag instances\label{alg:bbrc-sample}}
\end{algorithm2e*}
Algorithm \ref{alg:bbrc-sample} switches between out-of-bag estimation and ordinary discriminative graph mining (ODGM).
We consider the former first.  Line 4
creates a hash table to gather results from mining bootstrap samples 
(line 7). The resulting subgraphs are matched on the out-of-bag instances (line
8), and the results are stored in the hash. On termination of the loop, each hash
entry $\mathbf{k_i}$ has at most $N$ support values. Post-processing the results
incurs negligible overhead. It
consists of removing subgraphs that (line 11) do not have enough entries in the hash table, as
determined by $minHashLength$, or which (line 13) do not significantly
deviate from the overall distribution of classes, as assessed by the significance
test (section \ref{ss:significance-test}), with contingency table calculated
according to mean (section \ref{ss:simple-mean}) or maximum likelihood
estimation (section \ref{ss:MLE}) method (line 12). 

If $method=ODGM$, the data (support value, $p$-value, and bias) is obtained from a single BBRC run on the full training data, without bootstrapping and out-of-bag estimation (line 2).



\section{Experiments}
\label{s:Experiments}

\subsection{Setup} 
\label{ss:Error-estimation} 
Three methods were compared by their ability to estimate the discriminative
potential of subgraphs, by assessing the deviations between the class specific
support values, $p$-values, and biases of subgraphs, as a) estimated by the respective
method, and b) obtained by matching the subgraphs onto an independent test set.
The methods are provided by Algorithm \ref{alg:bbrc-sample}:
\begin{enumerate} 
  \item MLE: Out-of-bag estimation with Algorithm \ref{alg:bbrc-sample}, according
    to section \ref{ss:MLE}, with $numBoots=100$.
  \item MEAN: Out-of-bag estimation with Algorithm \ref{alg:bbrc-sample}, according
    to section \ref{ss:simple-mean}, with $numBoots=100$.
  \item ODGM: Ordinary discriminative graph mining.
\end{enumerate}

The process was repeated 100 times for the three methods, with minimum hash entry length 
of 30 for each subgraph, to ensure a statistically reliable number of support values. 

\begin{figure*}[t]
  \begin{minipage}[h]{.59\textwidth}
    \begin{algorithm2e}[H]
      \fontsize{8}{10}
      \selectfont
      \SetAlgoInsideSkip{medskip}
      \KwData{$graphDatabase, method\;\text{(MLE, MEAN, or ODGM)}, s$} 
      \KwResult{$E_1, E_2, E_3, E_4, E_5$}
      $E_1 =  E_2 =  E_3 =  E_4 =  E_5 =  \left[ \right]$\;
      \For{$i:=1 \to 100$}{
        $[trainSet, testSet] \leftarrow splitStratified(graphDatabase,0.5)$\;
        $\left[ subgraphs, values^B \right] \leftarrow Algorithm\,\ref{alg:bbrc-sample}(trainSet,100,30,method,s,0.05)$\;
        $\left[ subgraphs, values^T \right] \leftarrow match(subgraphs, testSet)$\;
        \For{$j:=1 \to 5$}{
          $E_j \leftarrow \left[ E_j, errorJ(values^T, values^B) \right]$\;
        }
      }
      \caption{\textbf{Calculation of error measures}\label{alg:pValEstimate}}
    \end{algorithm2e}
  \end{minipage}
  \begin{minipage}[h]{.39\textwidth}
    \input{winloss}
  \end{minipage}
\end{figure*}

The whole procedure is described in Algorithm \ref{alg:pValEstimate}.
Line 1 initializes empty vectors that capture the residuals in estimation.
Inside the main loop, stratified splitting (such that proportions of classes
inside each split equal overall proportions) generates a training and a test
set of equal size. The training set is treated by the selected method, which
returns a vector of subgraphs and a vector $values^B$ of values,
including support values, $p$-values, and bias (line 5). The subgraphs are matched on
the test set, yielding analogous values $values^T$ (line 6). Finally, 
residual vectors $E_1-E_5$ capture the differences between $values^B$ and
$values^T$.

Five different
error measures were assessed to compare the methods:
\begin{enumerate}
  \item $E_1$, the mean of     $ p^B -p^T \,$                                                                                    over subgraphs, i.e. the bias of $p$-value errors.
  \item $E_2$, the mean of     $ \Big|\,p^B -p^T \,\Big|$                                                                        over subgraphs, i.e. the absolute $p$-values errors.
  \item $E_3$, the mean of     $ \Big(\,\frac{1}{|I|} \sum_{i=1}^{|I|} \,\Big|\,\frac{k^B_i}{k^B} - \frac{k^T_i}{k^T} \,\Big|\,\Big)$ over subgraphs, i.e. the relative support value errors.
  \item $E_4$, One minus the mean of $ \delta(p^B \le \alpha, p^T \le \alpha)$                                                         over subgraphs, i.e. the fraction wrongly recognized as significant.
  \item $E_5$, One minus the mean of $ \delta(bias^B, bias^T)$                                                                        over subgraphs, i.e. the fraction with wrongly recognized class bias.

\end{enumerate}
In the above, $\delta(\cdot,\cdot)$ is the Kronecker function, which returns 1, if the arguments are equal, and 0 else.

Six molecular, class labeled datasets were used in the experiments. 
Four were drawn from the carcinogenic potency database
(CPDB)\footnote{\url{http://potency.berkeley.edu/cpdb.html}}, namely 
``Combined Carcinogenicity and Mutagenicity'' (MUL, 4 classes, 677 compounds),
``Mouse Carcinogenicity'' (MOU, 2 classes, 914 compounds), 
``Multi-Cell Call'' (MCC, 2 classes, 1050 compounds), and 
``Rat Carcinogenicity'' (RAT, 2 classes, 1128 compounds). 
MUL's labels consist of the four cross-combinations of binary carcinogenicity
and mutagenicity labels from the CPDB, for all chemicals with both values for
both labels present.
A rather small dataset, describing human intestinal absorption (INT, 3 classes,
458 compounds) \cite{Suenderhauf10Combinatorial}, as well as the rather large
Kazius/Bursi mutagenicity dataset (KAZ, 2 classes, 4069 compounds),
\cite{kazius05derivation} were also used.  An appropriate value for minimum
support (parameter $s$ in Algorithm \ref{alg:pValEstimate}) was determined a
priori for each $G_{Train}$ and kept constant.

\subsection{Results}
\input{anal}
\label{ss:Results}
\begin{figure*}[t]
  \begin{minipage}[h]{5.5cm}
    \includegraphics[width=5.5cm]{lp3.eps}
  \end{minipage}
  \begin{minipage}[h]{5.5cm}
    \includegraphics[width=5.5cm]{lp4.eps}
  \end{minipage}
  \begin{minipage}[h]{5.5cm}
    \includegraphics[width=5.5cm]{lp5.eps}
  \end{minipage}
  \caption{Error measures along increasing logarithmic dataset size}
  \label{fig:lp}
\end{figure*}
Table \ref{t:anal} details the results in the form of mean values and standard
deviations across $N=100$ bootstraps for all error measures.  
Figure
\ref{t:winloss} shows win/loss statistics. It compares out-of-bag methods MLE
and MEAN with ODGM, by pooling the former (OOB). This is possible, since they
showed uniform win/loss behaviour against ODGM.
It also compares MLE against MEAN.
Numbers indicate the total amount of wins, numbers in brackets the
subset of significant wins, as obtained by Wilcoxon signed rank tests ($p=0.001$).

E1 and E2 measure the numerical bias and error on the $p$-value threshold that determines whether
a subgraph is included in the result set.  E3, E5, and E4 describe errors on
relative support values, class bias, and significance (as a binary attribute),
respectively.  The latter measures are readily interpretable, thus we discuss
them separately from E1 and E2.

We first consider E1 and E2. Judging from Table \ref{t:anal}, for four datasets
(apart from INT and KAZ), there is a clear improvement when out-of-bag
methods are applied, compared to single runs of discriminative
subgraph mining. The advantages for OOB methods over ODGM are lowest for datasets MOU and INT.
For INT, $p$-value bias (E1)
is much smaller, but not $p$-value error (E2). In the significance
tests, a difference to ODGM could not be found here. All other pairs of OOB 
methods against ODGM were significantly different. For KAZ, E1 and
E2 are so low, that they do not show in Table \ref{t:anal}, due to rounding. However,
the differences are statistically significant, also for KAZ.

Comparing OOB methods among each other, both show
similar values, according to Table \ref{t:anal}. Both seem to be relatively
unbiased (E1), however, Figure \ref{t:winloss} shows that MEAN seems to have
advantages over MLE. For absolute error (E2), the situation is less clear. 

We now consider E3, E4, and E5. 
For E3, the relative support value error,
OOB methods estimate the support values always better than ODGM, as Table \ref{t:anal} shows. However, the difference was not significant for INT and KAZ.
MLE does always better than MEAN, and most of the time significantly better.

For E4, the error on binary significance estimation, ODGM errors are very large:
Most of the time, the majority of subgraphs were falsely estimated as significant. 
MLE and MEAN do both much better for all datasets, also significantly better, except for KAZ. 
Also, MLE performs better than MEAN in
all cases except KAZ (three times with significant difference). 

For E5, the class bias error, both MLE and MEAN drastically improve on ODGM, as
Table \ref{t:anal} shows. The differences
are statistically significant for all datasets, except KAZ. Between MLE and MEAN, practically no significant differences could be found.

Table \ref{t:anal} also gives the mean number of subgraphs generated in the
last column. Much less subgraphs are generated by OOB methods. 
There is a general trend for lower fractions of subgraphs
with shrinking dataset sizes, compared to ODGM. 
%This reflects the higher uncertainty due to the lack of data. 
%However, as the line plots in
%Figure \ref{fig:lp} show, there is a trend towards a higher gap in errors
%between the sampling methods on the one hand, and ODGM on the other hand with
%shrinking dataset sizes. It becomes also clear from these plots, that SAL
%behaves different than the other datasets (as discussed before).


\section{Discussion and Conclusions}
\label{s:Conclusion}
Especially for rather small databases, which are typical in the field of
toxicology, the proposed methods can significantly improve on the estimation of
statistical quantities, compared to ordinary discriminative graph mining. 
Thus, for such settings, we conclude that it does not to suffice treat database graphs in a single pass, as is
done by ordinary discriminative graph mining, in order to obtain significantly class-associated
subgraphs. Instead, resampling methods
should be used that repeatedly assess subgraph significance on data sets that obtained by perturbations to the training data. To validate the
data, out-of-bag estimation is a feasible approach. The procedure may also be
embedded in a workflow to to learn a bagged predictor.

We investigate the interpretable error measures E3, E4, and E5 again in
the charts in Figure \ref{fig:lp}, where their values are plotted along
increasing dataset size. The latter was logarithmically transformed, to
visually better separate similarly sized datasets MOU, MCC, and RAT. 

Along the three smallest datasets, error measures vary.  However, the difference
to ODGM is always pronounced (apart from KAZ), and for all methods, the variations per method
are similar along the datasets. For the KAZ dataset, there is no advantage for OOB methods.
%The two multi-class datasets are the smallest datasets. We were not able to obtain larger multi-class datasets.

The estimation of the prominent class for each subgraph, captured by E5, is
obviously the easiest task. Apart from MUL, OOB methods have E5 values close to
zero. The corresponding values for ODGM are disturbingly high.

E3 and E4 are related: $p$-values, analyzed in E4, are based on the support
values, which are the subject of E3.  The improvements provided by OOB methods
in the estimation of support values seems to help the estimation of
significance a lot, as the slopes of the lines are similar, but the difference
to ODGM is much larger for the latter.

For larger datasets, there is a trend towards increasing performance for all
methods, as indicated by dashed lines.
We attribute this to the increasing precision of ODGM (which is wrapped by the
OOB methods) in the presence of more learning data. However, the fraction of
circa 50 \% of subgraphs wrongly determined by ODGM in E4 even for the second
largest dataset (RAT) indicates that mining significant subgraphs from training
data directly is not reliable. Only for the KAZ dataset, E4 drops to levels
similar to OOB methods.

\bibliography{bbrc-sample}
\bibliographystyle{plain}

\end{document}
