% This is "sig-alternate.tex" V1.9 April 2009
% This file should be compiled with V2.4 of "sig-alternate.cls" April 2009
%
% This example file demonstrates the use of the 'sig-alternate.cls'
% V2.4 LaTeX2e document class file. It is for those submitting
% articles to ACM Conference Proceedings WHO DO NOT WISH TO
% STRICTLY ADHERE TO THE SIGS (PUBS-BOARD-ENDORSED) STYLE.
% The 'sig-alternate.cls' file will produce a similar-looking,
% albeit, 'tighter' paper resulting in, invariably, fewer pages.
%
% ----------------------------------------------------------------------------------------------------------------
% This .tex file (and associated .cls V2.4) produces:
%       1) The Permission Statement
%       2) The Conference (location) Info information
%       3) The Copyright Line with ACM data
%       4) NO page numbers
%
% as against the acm_proc_article-sp.cls file which
% DOES NOT produce 1) thru' 3) above.
%
% Using 'sig-alternate.cls' you have control, however, from within
% the source .tex file, over both the CopyrightYear
% (defaulted to 200X) and the ACM Copyright Data
% (defaulted to X-XXXXX-XX-X/XX/XX).
% e.g.
% \CopyrightYear{2007} will cause 2007 to appear in the copyright line.
% \crdata{0-12345-67-8/90/12} will cause 0-12345-67-8/90/12 to appear in the copyright line.
%
% ---------------------------------------------------------------------------------------------------------------
% This .tex source is an example which *does* use
% the .bib file (from which the .bbl file % is produced).
% REMEMBER HOWEVER: After having produced the .bbl file,
% and prior to final submission, you *NEED* to 'insert'
% your .bbl file into your source .tex file so as to provide
% ONE 'self-contained' source file.
%
% ================= IF YOU HAVE QUESTIONS =======================
% Questions regarding the SIGS styles, SIGS policies and
% procedures, Conferences etc. should be sent to
% Adrienne Griscti (griscti@acm.org)
%
% Technical questions _only_ to
% Gerald Murray (murray@hq.acm.org)
% ===============================================================
%
% For tracking purposes - this is V1.9 - April 2009

\documentclass{sig-alternate}
  \pdfpagewidth=8.5truein
  \pdfpageheight=11truein

\makeatletter
\newif\if@restonecol
\makeatother
\let\algorithm\relax
\let\endalgorithm\relax


\usepackage{multirow}	% for tables
\usepackage{graphicx}   % for including EPS
\usepackage{rotating}
\usepackage{url}

% % % Special mathematical fonts
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{bm}
\usepackage{srctex}
\usepackage[linesnumbered,algo2e,noend]{algorithm2e}
\usepackage{algpseudocode}
\usepackage{setspace}
%\usepackage[compact]{titlesec}
\usepackage{mdwlist}
%\usepackage[left=2cm,top=1cm,right=2cm,nohead,nofoot]{geometry}

\algnotext{EndFor}
\algnotext{EndIf}

\begin{document}
%
% --- Author Metadata here ---
\conferenceinfo{SAC'13}{March 18-22, 2013, Coimbra, Portugal.}
\CopyrightYear{2013} % Allows default copyright year (2002) to be over-ridden - IF NEED BE.
\crdata{978-1-4503-1656-9/13/03}  % Allows default copyright data (X-XXXXX-XX-X/XX/XX) to be over-ridden.
% --- End of Author Metadata ---

\title{Out-Of-Bag Discriminative Graph Mining}
%
% You need the command \numberofauthors to handle the 'placement
% and alignment' of the authors beneath the title.
%
% For aesthetic reasons, we recommend 'three authors at a time'
% i.e. three 'name/affiliation blocks' be placed beneath the title.
%
% NOTE: You are NOT restricted in how many 'rows' of
% "name/affiliations" may appear. We just ask that you restrict
% the number of 'columns' to three.
%
% Because of the available 'opening page real-estate'
% we ask you to refrain from putting more than six authors
% (two rows with three columns) beneath the article title.
% More than six makes the first-page appear very cluttered indeed.
%
% Use the \alignauthor commands to handle the names
% and affiliations for an 'aesthetic maximum' of six authors.
% Add names, affiliations, addresses for
% the seventh etc. author(s) as the argument for the
% \additionalauthors command.
% These 'additional authors' will be output/set for you
% without further effort on your part as the last section in
% the body of your article BEFORE References or any Appendices.

\numberofauthors{3} %  in this sample file, there are a *total*
% of EIGHT authors. SIX appear on the 'first-page' (for formatting
% reasons) and the remaining two appear in the \additionalauthors section.
%
\author{
% You can go ahead and credit any number of authors here,
% e.g. one 'row of three' or two rows (consisting of one row of three
% and a second row of one, two or three).
%
% The command \alignauthor (no curly braces needed) should
% precede each author name, affiliation/snail-mail address and
% e-mail address. Additionally, tag each line of
% affiliation/address with \affaddr, and tag the
% e-mail address with \email.
%
% 1st. author
\alignauthor
Andreas Maunz\\
       \affaddr{Institute for Physics}\\
       \affaddr{Hermann-Herder-Str. 3}\\
       \affaddr{79194 Freiburg, Germany}\\
       \email{andreas@maunz.de}
% 2nd. author
\alignauthor David Vorgrimmler\\
       \affaddr{in-silico Toxicology}\\
       \affaddr{Altkircherstr. 4}\\
       \affaddr{4054 Basel, Switzerland}\\
       \email{vorgrimmler@in-silico.ch}
% 3rd. author
\alignauthor 
Christoph Helma\\
       \affaddr{in-silico Toxicology}\\
       \affaddr{Altkircherstr. 4}\\
       \affaddr{4054 Basel, Switzerland}\\
       \email{helma@in-silico.ch}
}

\maketitle
\begin{abstract}
  In class-labeled graph databases, each graph is associated with one from a
finite set of classes.  This induces associations between subgraphs
occurring in these graphs, and the classes. The subgraphs with strong
class associations are called discriminative subgraphs.  In this work,
discriminative subgraphs are repeatedly mined on bootstrap samples of a graph
database in order to estimate the subgraph associations precisely.  This is
done by recording the subgraph frequencies (support values) per class over the
out-of-bag instances of the bootstrap process.  We investigate two different
methods for the approximation of the true underlying support values from these
empirical values, involving sample mean and maximum likelihood estimation.  We
show that both methods significantly improve the process, compared to single
runs of discriminative graph mining, by applying the different methods to
publicly available, chemical datasets.  In computational models of toxicology,
subgraphs (fragments of chemical structure) are routinely used to describe
toxicological properties of molecules. Apart from the subgraph associations being
statistically validated, the subgraph sets created by the proposed methods are
also small, compared to ordinary graph mining, and may thus be beneficial
for statistical models, as well as for inspection by toxicological experts.


\end{abstract}



% A category with the (minimum) three required fields
\category{H.2.8}{Database Applications}{Data Mining, Statistical Databases}
\terms{Theory, Experimentation, Performance}

\section{Introduction}
\label{s:Introduction}
Given a class-labeled graph database, discriminative graph mining is a
supervised learning task with the goal to extract graph fragments (subgraphs)
with strong associations to the classes, according to statistical constraints
set by the user. For example, the subgraphs may be molecular fragments that
induce toxicity. Indeed, finding such subgraphs is a major goal in toxicology
\cite{kazius05derivation}. However, discriminative graph mining yields large
result sets, even for very tight constraints on subgraph significance ($p$-values) \cite{Jun04Spin}. Moreover, it is an unstable
process, i.e. slight changes in the sample may lead to substantially different subgraph
sets. 

A bagged predictor consists of several aggregate predictors, each trained on a
dedicated bootstrap sample of the training data. Bagged predictors have the
potential for considerably higher predictive accuracy, compared to single
predictors, especially in the context of unstable prediction methods
\cite{breiman96oob}. Bagged predictor estimates may be obtained from the out-of-bag
instances, which saves computational effort compared to crossvalidation on the
bootstrap samples. For example, out-of-bag estimation of node errors in
decision trees could improve on estimates obtained from the training data as a
whole \cite{breiman96oob}.

This work extends discriminative subgraph mining by out-of-bag estimation for
subgraph frequencies (support values) on the classes that govern the
training data, and by aggregating subgraphs in the output that pass the
statistical constraints.  Infrequently occurring subgraphs are filtered out, 
which removes the instability to a large extent. The
result is a set of statistically validated, highly significant,
discriminative subgraphs, which may be useful for diagnostic or predictive
modelling, or for expert inspection. 

The remainder of this work is structured as follows: We present related work
with a focus on discriminative graph mining (section \ref{s:relatedWork}), our
proposed methods for out-of-bag estimation of support values and $p$-values, as
well as algorithmic implementation (section \ref{s:Methods}).
Experiments include validation of support
values and $p$-values on publicly available databases of
various sizes and numbers of classes (section \ref{s:Experiments}).
We draw conclusions in section \ref{s:Conclusion}.
The contributions of this work are summarized as follows:
\begin{itemize*}
  \item Repeated discriminative graph mining on bootstrap samples of a
    class-labeled graph database is proposed as a means to stabilize estimates
    for subgraph properties, such as support values per class, compared to
    single runs of discriminative graph mining. The estimation is performed
    using the out-of-bag instances of the individual bootstrap samples.
  \item Two methods for the estimation of support values are described, where both
    handle multiple classes. Significance tests are applied to these
    estimated values and insignificant subgraphs are removed from the results.  
  \item The estimated support values, $p$-values, and class
    associations are empirically validated on molecular databases of various
    sizes.  The results indicate significant improvements over 
    ordinary discriminative graph mining, where the effect is generally larger the
    smaller the datasets are.  We conclude that out-of-bag estimation has 
    potential to generate concise, discriminative subgraph sets for
    use in statistical models and/or expert inspection.
\end{itemize*}


\section{Related Work}
\label{s:relatedWork}

Out-of-bag methods have been used to robustly estimate node probabilities and
node error rates in decision trees \cite{breiman96oob} as well as the
generalization error and accuracy of bagged predictors. In the work by Bylander
\cite{bylander02estimating}, generalization error was well modeled by
out-of-bag estimation, and its already small bias could be further reduced by a
correction method, where, in order to correct the prediction of a given
instance, similar out-of-bag instances with the same class were
employed. However, the method of out-of-bag estimation is not confined to these
examples, and may be used to estimate other statistical properties in
supervised learning.

Discriminative graph mining is often employed as a preprocessing step to
statistical learning, because discriminative subgraphs may be useful as descriptors
\cite{bringmann10lego}. Nowadays, there is a variety of well-known statistical
learning algorithms available ``off the shelf'', which makes a workflow
attractive where subgraphs are extracted from the data, represented in a
unified format, and fed into a machine learning algorithm \cite{hkr03molfea}.
Usually, discriminative subgraphs are mined from a graph database using a
predefined threshold with regard to its association to the classes. A subgraph
qualifies for the result set if it passes the corresponding significance test.
However, such approaches tend to produce huge sets of very similar subgraphs,
even with very tight bounds on discriminative power, which would prevent
machine learning methods from building models in acceptable time.  Thus,
post-processing would be required to lower redundancy and eliminate the vast
majority of subgraphs \cite{Hasan_origami:mining,Jun04Spin}.  Moreover, the
result is not stable with regards to perturbations of the database.

Subgraph boosting \cite{saigo09gboost} is an integrated approach to build models on
small sets of subgraphs, alternating between graph mining and model building. The method presented here is clearly
different from boosting, because it calculates subgraphs independently from a specific model.  It is similar in that it calculates a small
collection of discriminative subgraphs, but it is also stable against
perturbations of the database, which is generally not the case for boosting.


\section{Methods}
\label{s:Methods}

\subsection{Basic Graph Theory}
\label{ss:BasicGraphTheory}
A graph database is a tuple $(G, \Sigma, a)$, where $G$ is a set of graphs,
$\Sigma \ne \emptyset$  is a totally ordered set of labels and $a: G
\rightarrow C$, $C \subset \mathbb{N}$, is a function that assigns one from a
finite set of class values to every graph in the database.  The set of target
classes $C$ consists of at least two values.  We consider labeled, undirected
graphs, i.e. tuples $g=(V,E,\Sigma,\lambda)$, where $V\ne \emptyset$ is a
finite set of nodes and $E \subseteq V = \{\{v_1, v_2\} \in \{V \times V\}, v_1
\ne v_2\}$ is a set of edges and $\lambda: V\cup E \rightarrow \Sigma$ is a
label function.  
An ordered set of nodes $\{ v_1, \ldots, v_m\}$ is a \emph{path} between $v_1$ and $v_m$, if $\{v_i, v_{i+1}\} \in E, i \in \{1,\ldots,m-1\}$ and $v_i \neq v_j$ for all $i,j\in \{1,\ldots,m\}$.
We only consider connected graphs here, i.e.  there is a path
between each two nodes in the graph.

A graph $g'=(V',E',\Sigma',\lambda')$ subgraph-isomorphic to $g$ if $V'
\subseteq V$ and $E' \subseteq E$ with $V' \ne \emptyset$ and $E' \ne
\emptyset$, $\lambda'(v_1)=\lambda(v_2)$ whenever $v_1=v_2$, and
$\lambda'(e_1)=\lambda(e_2)$ whenever $e_1=e_2$, for all nodes and edges in
$g'$. Then, graph $g'$ is also referred to as a subgraph of $g$ -- we also say
that $g'$ covers $g$.  The subset of the database instances $G$ that $g'$
covers is referred to as the occurrences of $g'$, and its size as (total) support of
$g'$.  As a special case, the size of the subset of occurrences with $a(g)=i$,
for any $g$ in the occurrences, is referred to as the support of $g'$ for class
$i$. Thus, any subgraph has associated support values per class, ranging each
between 0 and the support of $g'$, and summing up to the the support of $g'$.

The subgraphs considered in this work are free subtrees. Here, we define a tree
as a graph with exactly $n-1$ edges that connect its $n$ nodes. A free tree is
a tree without a designated root node. For an introduction to tree mining and
the terminology used there, see the overview by Chi \emph{et al.}
\cite{CMNK01Frequent}.

\subsection{Significance Test}
\label{ss:significance-test}
% general chisq test
For a given subgraph $g$, we seek a $|I| \times 2$ contingency table that lists the
support values per class in the first column and the overall distribution of target
classes in the second column, as in Table \ref{t-ContingencyTableIndTest}.
\begin{table}[t]
  \centering
  \begin{tabular}{|l|l|l|}
    \hline
    ~           &	$g$       & $all$       \\\hline
    class 1	    &	$k_1$     & $|G^1|$     \\\hline
    class 2 	  &	$k_2$     & $|G^2|$     \\\hline
    $\ldots$ 	  &	$\ldots$  & $\ldots$    \\\hline
    class $|I|$	&	$k_{|I|}$ & $|G^{|I|}|$ \\\hline
    $\Sigma$	  &	$k$       & $|G|$       \\\hline
  \end{tabular}
  \caption[]{Contingency table for subgraph $g$.}
  \label{t-ContingencyTableIndTest}
\end{table}
This data serves to check whether $g$'s support values differ
significantly from the overall class distribution.  The $\chi^2_d$ function for
distribution testing, defined as
\begin{equation}
  %\chi^2_d(x,y) = \frac{(y-\frac{xm}{n})^2}{\frac{xm}{n}} + \frac{(x-y-\frac{x(n-m)}{n})^2}{\frac{x(n-m)}{n}},
  \chi^2_d(x,y) = \sum_{i=1}^{|I|} \frac{(k_i-E(k_i))^2}{E(k_i)},
  \label{eq:chid}
\end{equation} 
where $E(k_i)=\frac{G^{i}k}{|G|}$ is the expected value of $k_i$, calculates
the sum of squares of deviations from the expected support for all target
classes. The function value is then compared against the $\chi^2$
distribution function to obtain a $p$-value and conduct a significance test with
$|I|-1$ degrees of freedom.  The next sections discuss methods to obtain the
$k_i$ entries in the table from the support values obtained during bootstrapping (section
\ref{ss:oob-dgm}).  The $|G^{i}|$ entries are constants and take the values of
the overall $|G^{i}|$.  This is possible due to the stratified bootstrapping approach,
which maintains the overall class proportions in each sample (see section
\ref{ss:oob-dgm}). 
Additionally, the bias of $g$ is determined as $\arg\max_i (\frac{k_i}{k}/\frac{G^i}{G})$, to designate the dominant class for $g$.



\subsection{Out-Of-Bag Discriminative Graph Mining}
\label{ss:oob-dgm}
We refer to the subset that contains all the graphs $g \in G$
with $a(g)=i$ as $G^i$.  The procedure first splits the graph database 
into stratified, equal-sized training and test databases $G_{Train}$ and $G_{Test}$.
Subsequently, stratified bootstrapping is performed on $G_{Train}$, such
that each sample comprises $\vert G_{Train}^i\vert$ graphs associated with
class $i$, drawn with replacement and uniform probability inside each
class $i$.  On average, about 37\% (1/$e$) of training instances 
will not be drawn in any bootstrap sample (out-of-bag instances). 
Next, discriminative subgraphs are mined from the drawn instances,
according to minimum total support and significance thresholds. 
This results in a set of subgraphs, where each subgraph has associated support values, $p$-value, and bias.
Finally, the method re-assesses the support values of the subgraphs in the result set by performing isomorphism
tests with the subgraphs on the out-of-bag instances (``matching''), and stores these values.

After the inital split, bootstrapping and graph mining is repeated $N$ times on $G_{Train}$, where in each
iteration, pairs of subgraphs and out-of-bag support values per class
$(g,k_1,\ldots,k_{\vert I\vert})$ are produced, meaning that subgraph $g$
occurs in $k_i$ out-of-bag graphs associated with class $i$. The results are
recorded over the $N$ bootstrap samples, such that for each $g$, the list of
support values is a tuple $(\mathbf{k_1}\ldots\mathbf{k_{\vert I\vert}})$,
where $\mathbf{k_i}$ is a vector $(k_i^1\ldots k_i^N)$, containing all the
support values.  
The total support is determined from the class specific support values by
summing up vectors $\mathbf{k_i}$ across classes:
$\mathbf{k}=\sum_{i=1}^{\vert I\vert} \mathbf{k_i}$. The vectors $\mathbf{k_i}$
are generally sparse (contain missing values), due to the instability of discriminative graph mining,
i.e. perturbations to the dataset (such as bootstrap sampling) yield almost
always a different (but partially overlapping) selection of subgraphs. To cope with the
variety of rare subgraphs, a fixed threshold removes all subgraphs with less
than $\lfloor0.3*N\rfloor$ entries in the list of support values, after the end
of bootstrapping.

Finally, support values are estimated for each remaining
subgraph from the recorded results. Two methods are employed (described in the next sections), based either
on the sample mean support per class, and using data of the current subgraph
only, or on a maximum likelihood estimate, involving some of the other
subgraphs. Then, the significance test from section \ref{ss:significance-test}
is run on the estimated support values. 

\subsubsection{Sample Mean Method}
\label{ss:simple-mean}
We set the value of $k_i$ in Table \ref{t-ContingencyTableIndTest} to
$\overline{\mathbf{k_i}}$ for all $i \in \{1,\ldots,|I|\}$, i.e. the sample mean
across the entries of vector $\mathbf{k_i}$, ignoring missing values. The
value of $k$ is the sum of the $k_i$.

\subsubsection{Maximum Likelihood Estimation Method}
\label{ss:MLE}
Here, we employ some of the other subgraphs to form estimates for the $k_i$.
The first step in this process is to extract the subgraphs with the same class
bias as $g$ (see section \ref{ss:significance-test}).  Local ties are broken in
favor of the dominant global class. In case of a further tie on the global
level, one of the globally dominant classes is chosen with uniform probability.
In a second step, the subgraphs with the same class bias as $g$ are used to correct
$g$'s local frequencies by weighting. This approach has some similarity to the
work by Bylander \cite{bylander02estimating}, however, his aim is to correct
instance predictions, and his correction employs similar out-of-bag instances,
whereas our correction happens across bootstraps, and on the subgraphs (not
instances) obtained collectively from all the bootstrap samples.  For each
class, we model the event that each $k_i^j \in \mathbf{k_i}$ would occur for
each of the subgraphs with the same class bias as $g$ as a multinomial
selection process.  More specifically, we determine the class probabilities for
each subgraph $g'$ with the same class bias as $g$ with a maximum likelihood
estimator. It is the smoothed vector of relative class specific support values,
defined as:
\begin{equation}
  \mathbf{\alpha_{g'}} = \left(\frac{1+\vert\mathbf{k_1}\vert_1}{\vert I\vert+\vert\mathbf{k}\vert}_1,\ldots,\frac{1+\vert\mathbf{k_{\vert I\vert}}\vert_1}{\vert I\vert+\vert\mathbf{k}\vert_1}\right)
  \label{eqn:mlexpr}
\end{equation}
where the $\mathbf{k_i}$ and $\mathbf{k}$ pertain to $g'$, and $\vert\cdot\vert_1$ is the one-norm (the sum of the vector elements ignoring missing values). Following that, for
each non-missing tuple $(k_1^j,\ldots,k_{\vert I\vert}^j)$ pertaining to $g$, a probability distribution is
determined from this collection of multinomials:
\begin{equation}
  p((k_1^j,\ldots,k_{\vert I\vert}^j))=\frac{\sum_{g'} p((k_1^j,\ldots,k_{\vert I\vert}^j); \mathbf{\alpha_{g'}})}{\sum_{g'}1}
  \label{eqn:avgpr}
\end{equation}
Finally, the $k_i^j$ values pertaining to $g$ are corrected in a weighted average
based on this probability distribution:
\begin{equation}
  \overline{\mathbf{k_i}}=\frac{\sum_j k_i^j p((k_1^j,\ldots,k_{\vert I\vert}^j))}{\sum_j p((k_1^j,\ldots,k_{\vert I\vert}^j))}
  \label{eqn:avgki}
\end{equation}
Again, we set the value of $k_i$ in Table \ref{t-ContingencyTableIndTest} to $\overline{\mathbf{k_i}}$.

\subsection{Algorithm}
\label{s:Algorithm}
%\begin{figure*}[t]
%  \begin{center}
%    \includegraphics[width=9cm]{classes.eps}
%  \end{center}
%  \caption{Two non-disjoint partitions $(a,b,d)$ and $(a,c,d)$. The members are ordered by subgraph relationship.}
%  \label{fig:bbrc}
%\end{figure*}
%According to section \ref{ss:oob-dgm}, graph mining proceeds in two steps:
%mining the given bootstrap sample and -- for each subgraph found -- looking up
%support values per class by matching on the out-of-bag instances.  
The mining step from section \ref{ss:oob-dgm} may be 
implemented using a discriminative graph mining algorithm of choice. Here, we
employ backbone refinement class mining (BBRC) \cite{maunz11efficient}. It
achieves high compression by partitioning the subgraph search space into non-disjoint sets (classes) with the same
longest paths (backbones) and selecting only one representative from each
class. 
%Inside each partition, the patterns are ordered by the subgraph relationship (see figure \ref{fig:bbrc}). 
The representative is chosen to minimize the $p$-value (section \ref{ss:significance-test}), unless no member passes the user-defined significance constraint, in which case no representative is chosen.
The search is also bounded by minimum total support, as described in section \ref{ss:oob-dgm}.
In the BBRC output, two isomorphic subgraphs are always represented by the same string identifier.
We employ SMARTS strings as identifiers, a kind of regular expression to encode
molecular fragments as strings\footnote{see \url{http://www.daylight.com/dayhtml/doc/theory/theory.smarts.html}}.  This approach allows to store out-of-bag support values $\mathbf{k_i}$ in a
hash structure, using SMARTS as keys. The algorithm using $numBoots=N$ bootstrap samples is shown in Algorithm
\ref{alg:bbrc-sample}.

\begin{algorithm2e*}[t]
  \KwData{$dataBase, numBoots, minHashLength, method, minSupport, alpha$}
  \KwResult{$[subgraphs, values]$}
  \If{$numBoots=1$}{
     $[subgraphs, values] \leftarrow BBRC(dataBase, minSupport, alpha)$\;
  }
  \Else{
    $hashTable \leftarrow \{\}$\;
    \For{$i:=1 \to numBoots$ (Parallel Processing)} { 
      $sample,OOB \leftarrow drawBsSample(dataBase)$\;
      $[subgraphs, values] \leftarrow BBRC(sample, minSupport, alpha)$\;
      $insert(hashTable,match(subgraphs,OOB))$\;
    }
    $[subgraphs, values] \leftarrow []$\;
    \For{$subgraph \in keys(hashTable)$}{
      \If{$length(hashTable[subgraph]) \geq minHashLength$}{
         $[candidateSupportValues, candidatePValue, candidateBias] \leftarrow method(hashTable[subgraph])$\;
        \If{$candidatePValue < alpha$}{
          $subgraphs \leftarrow subgraphs \cup subgraph$\;
          $values \leftarrow values \cup [candidateSupportValues, candidatePValue, candidateBias]$\;
        }
      }
    }
  }
  \caption{Calculation of subgraph significance on out-of-bag instances\label{alg:bbrc-sample}}
\end{algorithm2e*}
 We consider the case $numBoots>1$ first.  Line 4
creates an initially empty hash table to gather results from mining the bootstrap samples in
line 7. The resulting subgraphs are matched on the out-of-bag instances in line
8, and the results are stored in the hash. On termination of the loop, each hash
entry $\mathbf{k_i}$ has at most $N$ support values. Post-processing the results is
very fast and incurs negligible overhead compared to the graph mining step. It
consists of removing subgraphs that (line 11) do not have enough entries in the hash table, as
determined by $minHashLength$, or which (line 13) do not significantly
deviate from the overall distribution of classes, as assessed by the significance
test (section \ref{ss:significance-test}), with contingency table calculated
according to mean (section \ref{ss:simple-mean}) or maximum likelihood
estimation (section \ref{ss:MLE}) method (line 12). 

If $numBoots=1$, the data (support value, $p$-value, and bias) is obtained from a single BBRC run on the full training data, without bootstrapping and out-of-bag estimation.
%If $numBoots=1$, support values per
%class are obtained directly from a single BBRC run, without any matching (see
%section \ref{ss:Error-estimation}). Note that BBRC and matching compute support
%values, $p$-values and biases directly from their respective results.



\section{Experiments}
\label{s:Experiments}

\subsection{Setup} 
\label{ss:Error-estimation} 
Three methods were compared by their ability to estimate the discriminative
potential of subgraphs, by assessing the deviations between the class specific
support values, $p$-values, and biases of subgraphs, as a) estimated by the respective
method, and b) obtained by matching the subgraphs onto an independent test set.
The methods compared are
\begin{enumerate*} 
  \item MLE: Out-of-bag estimation with Algorithm \ref{alg:bbrc-sample}, according
    to section \ref{ss:MLE}, with $numBoots=100$.
  \item MEAN: Out-of-bag estimation with Algorithm \ref{alg:bbrc-sample}, according
    to section \ref{ss:simple-mean}, with $numBoots=100$.
  \item BBRC: The BBRC algorithm, with $numBoots=1$.
\end{enumerate*}

The process was repeated 100 times for methods 1, 2, and 3, with minimum hash entry length of 30 for each subgraph, to ensure a statistically reliable number of support values. Five different
error measures were assessed to compare the methods:
\begin{enumerate*}
  \item $E_1$, the mean of     $ p^B_i -p^T_i \,$                                                                                    over subgraphs, i.e. the bias of $p$-value errors.
  \item $E_2$, the mean of     $ \Big|\,p^B_i -p^T_i \,\Big|$                                                                        over subgraphs, i.e. the absolute $p$-values errors.
  \item $E_3$, the mean of     $ \Big(\,\frac{1}{|I|} \sum_{i=1}^{|I|} \,\Big|\,\frac{k^B_i}{k^B} - \frac{k^T_i}{k^T} \,\Big|\,\Big)$ over subgraphs, i.e. the relative support value errors.
  \item $E_4$, 1 - the mean of $ \delta(bias^B_i, bias^T_ix)$                                                                        over subgraphs, i.e. the fraction with wrongly recognized class bias.
  \item $E_5$, 1 - the mean of $ \delta(p^B_i \le \alpha, p^T_i \le \alpha)$                                                         over subgraphs, i.e. the fraction wrongly recognized as significant.
\end{enumerate*}

\begin{figure*}[t]
  \begin{minipage}[h]{.66\textwidth}
    \begin{algorithm2e}[H]
      \SetAlgoInsideSkip{medskip}
      \KwData{$graphDatabase, method, s$ (method is MLE, MEAN, or BBRC)} 
      \KwResult{$\mathbf{E_1},\mathbf{E_2},\mathbf{E_3},\mathbf{E_4},\mathbf{E_5}$}
      $\mathbf{E_1}=\mathbf{E_2}=\mathbf{E_3}=\mathbf{E_4}=\mathbf{E_5}=\left[ \right]$\;
      \For{$i:=1 \to 100$}{
        $[trainSet, testSet] \leftarrow splitStratified(graphDatabase,0.5)$ \;
        $numBoots \leftarrow 100;\;\textbf{if}\; method=BBRC\; numBoots \leftarrow 1$\;
        $\left[ subgraphs, values^B \right] \leftarrow Algorithm\,\ref{alg:bbrc-sample}(trainSet,100,30,method,s,0.05)$\;
        $\left[ subgraphs, values^T \right] \leftarrow match(subgraphs, testSet)$ \;
        \For{$j:=1 \to 5$}{
          $\mathbf{E_j} \leftarrow \left[ \mathbf{E_j}, errorJ(values^T, values^B) \right]$\;
        }
      }
      \caption{\textbf{Calculation of error measures}\label{alg:pValEstimate}}
    \end{algorithm2e}
  \end{minipage}
  \begin{minipage}[h]{.34\textwidth}
    \input{winloss}
  \end{minipage}
\end{figure*}

The whole procedure is described in Algorithm \ref{alg:pValEstimate}.
Line 1 initializes empty vectors that capture the residuals in estimation.
Inside the main loop, stratified splitting (such that proportions of classes
inside each split equal overall proportions) generates a training and a test
set of equal size. The training set is treated by the selected method, which
returns a vector of subgraphs and a vector $\mathbf{values^B}$ of values,
including support values, $p$-values, and bias (line 5). The subgraphs are matched on
the test set, yielding analogous values $\mathbf{values^T}$ (line 6). Finally, the
residual vectors capture the differences between $\mathbf{values^B}$ and
$\mathbf{values^T}$ by the error measures E1 - E5.

Six molecular, class labeled datasets were used in the experiments. 
Four were drawn from the carcinogenic potency database
(CPDB)\footnote{\url{http://potency.berkeley.edu/cpdb.html}}, namely 
``Combined Carcinogenicity and Mutagenicity'' (MUL, 4 classes, 677 compounds),
``Mouse Carcinogenicity'' (MOU, 2 classes, 914 compounds), 
``Multi-Cell Call'' (MCC, 2 classes, 1050 compounds), and 
``Rat Carcinogenicity'' (RAT, 2 classes, 1128 compounds). 
MUL's labels consist of the four cross-combinations of binary carcinogenicity
and mutagenicity labels from the CPDB, for all chemicals with both values for
both labels present.
A rather small dataset, describing human intestinal absorption (INT, 3 classes, 458 compounds) \cite{Suenderhauf10Combinatorial}, as well as
the rather large Kazius/Bursi mutagenicity dataset (KAZ, 2 classes, 4069 compounds), \cite{kazius05derivation} were also used.
An appropriate value for minimum support (parameter $s$ in Algorithm \ref{alg:pValEstimate}) was determined a priori for each dataset.

\subsection{Results}
\input{anal}
\label{ss:Results}
\begin{figure*}[t]
  \begin{minipage}[h]{5.5cm}
    \includegraphics[width=5.5cm]{lp3.eps}
  \end{minipage}
  \begin{minipage}[h]{5.5cm}
    \includegraphics[width=5.5cm]{lp4.eps}
  \end{minipage}
  \begin{minipage}[h]{5.5cm}
    \includegraphics[width=5.5cm]{lp5.eps}
  \end{minipage}
  \caption{Error measures along increasing logarithmic dataset size}
  \label{fig:lp}
\end{figure*}
Table \ref{t:anal} details the results in the form of mean values and standard
deviations across the 100 bootstraps for all error measures.  For meaures E3,
E4, and E5, Figure \ref{fig:lp} plots the mean values along increasing dataset
size, and Figure \ref{t:winloss} shows the win/loss statistics for MLE and
MEAN, as obtained by Wilcoxon signed rank tests ($p=0.001$). Numbers in brackets indicate the total amount of wins, bold numbers the
amount of significant wins among all.

E1 and E2 measure the numerical bias and error on the $p$-value threshold that determines whether
a subgraph is included in the result set.  E3, E4, and E5 describe errors on
relative support values, class bias, and significance (as a binary attribute),
respectively.  The latter measures are readily interpretable, thus we discuss
them separately from E1 and E2.

We first consider E1 and E2 in Table \ref{t:anal}. For four of the six datasets
(apart from INT and KAZ), there is a clear improvement when out-of-bag
estimation is applied (MLE or MEAN), compared to single runs of discriminative
subgraph mining (BBRC).  The differences for E1 and E2, between MLE or MEAN on
the one hand, and BBRC on the other hand, is lowest for datasets MOU and INT.
For the other datasets, they are much larger.  For INT, the $p$-value bias (E1)
is much smaller, but not $p$-value error (E2). In the significance
tests, a difference to BBRC could not be found. All other pairs of MLE or MEAN
against BBRC were significantly different (detailed results not shown).  For KAZ, E1 and
E2 are so low, that they do not show in the table, due to rounding. However,
the differences are statistically significant, also for KAZ.

Comparing out-of-bag estimation methods among each other, both methods have
similar values, according to Table \ref{t:anal}. They seem to be relatively
unbiased (E1). However, Figure \ref{t:winloss} shows that MEAN seems to have
advantages over MLE here. For absolute error (E2),  the situation is less clear. 

We now consider E3, E4, and E5.  For E3, the relative support value error, MLE
does always better than MEAN and BBRC, as Table \ref{t:anal} shows, most of the time significantly better,
compared to MEAN, except for KAZ.  Significant
differences between MLE or MEAN on the one hand, and BBRC on the other hand,
could not be found for INT and KAZ, but for all of the other datasets (test
results not shown). Figure \ref{t:winloss} shows that MLE does always
better than MEAN, most of the time significantly better.

For E4, the class bias error, both MLE and MEAN drastically improve on BBRC, as
Table \ref{t:anal} shows. In analogous test settings as for E3, the differences
are statistically significant for all datasets, except KAZ (test results not
shown). According to Figure \ref{t:winloss}, there are practically no
differences between MLE and MEAN.

For E5, the error on binary significance estimation, according to Table
\ref{t:anal}, the errors of ordinary discriminative graph mining are very large. MLE and MEAN are both significantly
better than BBRC for all datasets, except KAZ (test results not shown). Also, MLE performs better than MEAN in
all cases except KAZ (three times with significant difference) according to Figure
\ref{t:winloss}. 

Table \ref{t:anal} also gives the mean number of subgraphs generated in the
last column. Much less subgraphs are generated by the out-of-bag estimation methods. 
There is a general trend for lower fractions of subgraphs
for shrinking dataset sizes, compared to BBRC. 
%This reflects the higher uncertainty due to the lack of data. 
%However, as the line plots in
%Figure \ref{fig:lp} show, there is a trend towards a higher gap in errors
%between the sampling methods on the one hand, and BBRC on the other hand with
%shrinking dataset sizes. It becomes also clear from these plots, that SAL
%behaves different than the other datasets (as discussed before).


\section{Discussion and Conclusions}
\label{s:Conclusion}
This means that, despite getting closer to the test values
of support and $p$, it still judges a lot of subgraphs as significant at the
0.05 significance level, that are actually insignificant, or vice versa.  E4,
the estimation of class bias, is the easiest exercise. However, MLE and MEAN
perform significantly better than BBRC for all datasets except KAZ. The effect
is most drastic for the multi-class dataset MUL, but also remarkable for MOU
and RAT.



Especially for small graph databases, which are typical in toxicology, the
proposed methods can significantly improve on the estimation of statistical
quantities, compared to ordinary discriminative graph mining. For larger
datasets, this advantage shrinks, which we attribute to increasing accuracy of
ordinary discriminative graph mining in the presence of more data.


\bibliography{bbrc-sample}
\bibliographystyle{plain}

\end{document}
